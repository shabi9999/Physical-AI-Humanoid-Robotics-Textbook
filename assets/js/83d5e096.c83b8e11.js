"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[4335],{6460:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module2/ch5-unity-visualization","title":"Chapter 5: Unity Visualization & Human-Robot Interaction","description":"Why Add Unity to Gazebo?","source":"@site/docs/module2/chapter5-unity-visualization.md","sourceDirName":"module2","slug":"/module2/ch5-unity-visualization","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module2/ch5-unity-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/shabi9999/Physical-AI-Humanoid-Robotics-Textbook/tree/main/my-website/docs/module2/chapter5-unity-visualization.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Chapter 5: Unity Visualization & Human-Robot Interaction","module":2,"chapter":5,"id":"ch5-unity-visualization","learning_objectives":["Understand why combining Gazebo physics with Unity graphics creates powerful simulations","Connect Gazebo and Unity using ROS 2 bridges","Visualize humanoid robots with photorealistic rendering"],"prerequisites":["Chapters 1-4: All Module 2 content","Module 1: ROS 2 Fundamentals"],"related_chapters":["chapter1-digital-twin-concepts","chapter2-gazebo-physics","chapter3-world-building","chapter4-sensor-simulation"],"keywords":["Unity visualization","ROS 2 bridge","photorealistic rendering","human-robot interaction","HRI"],"difficulty":"Advanced","estimated_reading_time":"20 minutes","estimated_word_count":2600,"created_at":"2025-12-09","chunk_count":5,"searchable_terms":["Unity","visualization","ROS 2 bridge","photorealistic","HRI"]},"sidebar":"docs","previous":{"title":"Chapter 4: Sensor Simulation","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module2/ch4-sensor-simulation"},"next":{"title":"Module 3 Quickstart: Learning Path & Navigation Guide","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module3/intro"}}');var t=i(4848),s=i(8453);const a={sidebar_position:5,title:"Chapter 5: Unity Visualization & Human-Robot Interaction",module:2,chapter:5,id:"ch5-unity-visualization",learning_objectives:["Understand why combining Gazebo physics with Unity graphics creates powerful simulations","Connect Gazebo and Unity using ROS 2 bridges","Visualize humanoid robots with photorealistic rendering"],prerequisites:["Chapters 1-4: All Module 2 content","Module 1: ROS 2 Fundamentals"],related_chapters:["chapter1-digital-twin-concepts","chapter2-gazebo-physics","chapter3-world-building","chapter4-sensor-simulation"],keywords:["Unity visualization","ROS 2 bridge","photorealistic rendering","human-robot interaction","HRI"],difficulty:"Advanced",estimated_reading_time:"20 minutes",estimated_word_count:2600,created_at:"2025-12-09",chunk_count:5,searchable_terms:["Unity","visualization","ROS 2 bridge","photorealistic","HRI"]},r="Chapter 5: Unity Visualization & Human-Robot Interaction",l={},c=[{value:"Why Add Unity to Gazebo?",id:"why-add-unity-to-gazebo",level:2},{value:"How It Works: ROS 2 Bridge",id:"how-it-works-ros-2-bridge",level:2},{value:"ROS 2 Bridge Options",id:"ros-2-bridge-options",level:3},{value:"Gazebo-Unity Bridge Architecture Diagram",id:"gazebo-unity-bridge-architecture-diagram",level:3},{value:"Setting Up ROS 2 Bridge",id:"setting-up-ros-2-bridge",level:2},{value:"Step 1: Install Bridge Package",id:"step-1-install-bridge-package",level:3},{value:"Step 2: Start ROS 2 TCP Bridge",id:"step-2-start-ros-2-tcp-bridge",level:3},{value:"Step 3: Configure Unity",id:"step-3-configure-unity",level:3},{value:"Visualizing Robot State in Unity",id:"visualizing-robot-state-in-unity",level:2},{value:"Real-Time Pose Synchronization",id:"real-time-pose-synchronization",level:3},{value:"Sensor Data Visualization",id:"sensor-data-visualization",level:3},{value:"Human-Robot Interaction (HRI) Scenarios",id:"human-robot-interaction-hri-scenarios",level:2},{value:"Scenario 1: Human Avatar",id:"scenario-1-human-avatar",level:3},{value:"Scenario 2: Interactive Demonstration",id:"scenario-2-interactive-demonstration",level:3},{value:"Scenario 3: Handshake",id:"scenario-3-handshake",level:3},{value:"Advanced Visualization: Motion Planning",id:"advanced-visualization-motion-planning",level:2},{value:"Debugging Complex Behaviors",id:"debugging-complex-behaviors",level:2},{value:"Overlay Sensor Information",id:"overlay-sensor-information",level:3},{value:"Motion Analysis Tools",id:"motion-analysis-tools",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Latency: The Synchronization Challenge",id:"latency-the-synchronization-challenge",level:3},{value:"Frame Rate Management",id:"frame-rate-management",level:3},{value:"Deployment Scenarios",id:"deployment-scenarios",level:2},{value:"Local Machine (Development)",id:"local-machine-development",level:3},{value:"Two Machines (Remote)",id:"two-machines-remote",level:3},{value:"Cloud-Based",id:"cloud-based",level:3},{value:"Cross-Module Connections",id:"cross-module-connections",level:2},{value:"Creating a Complete HRI Demonstration",id:"creating-a-complete-hri-demonstration",level:2},{value:"Step 1: Design Scenario",id:"step-1-design-scenario",level:3},{value:"Step 2: Implement Robot Behavior (ROS)",id:"step-2-implement-robot-behavior-ros",level:3},{value:"Step 3: Implement HRI (Unity)",id:"step-3-implement-hri-unity",level:3},{value:"Step 4: Visualize and Debug",id:"step-4-visualize-and-debug",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Acronym Reference",id:"acronym-reference",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"What Comes Next?",id:"what-comes-next",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"chapter-5-unity-visualization--human-robot-interaction",children:"Chapter 5: Unity Visualization & Human-Robot Interaction"})}),"\n",(0,t.jsx)(n.h2,{id:"why-add-unity-to-gazebo",children:"Why Add Unity to Gazebo?"}),"\n",(0,t.jsx)(n.p,{children:"Gazebo is excellent for physics but has basic graphics. Unity provides:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Photorealistic rendering"}),": Beautiful, realistic 3D environments"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Human avatars"}),": Visualize humans interacting with robots"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Debugging tools"}),": Overlay sensor data, motion planning, trajectories"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Demonstrations"}),": Show stakeholders how robots work"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"HRI (Human-Robot Interaction)"}),": Simulate collaborative scenarios"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"The hybrid approach"}),": Gazebo physics + Unity graphics = best of both worlds."]}),"\n",(0,t.jsx)(n.h2,{id:"how-it-works-ros-2-bridge",children:"How It Works: ROS 2 Bridge"}),"\n",(0,t.jsxs)(n.p,{children:["A ",(0,t.jsx)(n.strong,{children:"ROS 2 bridge"})," connects Gazebo and Unity:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Gazebo                     ROS 2 Middleware              Unity\n(Physics)                  (Communication)              (Graphics)\n    \u2193                              \u2193                         \u2193\nRobot moves            \u2192     /robot/state topic      \u2192    Robot rendered\nSensors output         \u2192     /sensor/data topics     \u2192    Data visualized\nUser input (Unity)     \u2190     /command topics         \u2190    User clicks\n"})}),"\n",(0,t.jsx)(n.h3,{id:"ros-2-bridge-options",children:"ROS 2 Bridge Options"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Bridge"}),(0,t.jsx)(n.th,{children:"Support"}),(0,t.jsx)(n.th,{children:"Setup"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"ROS-TCP-Connector"})}),(0,t.jsx)(n.td,{children:"All versions"}),(0,t.jsx)(n.td,{children:"Medium"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Unity Robotics Hub"})}),(0,t.jsx)(n.td,{children:"Modern"}),(0,t.jsx)(n.td,{children:"Easy"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"LGSVL Simulator"})}),(0,t.jsx)(n.td,{children:"Advanced"}),(0,t.jsx)(n.td,{children:"Complex"})]})]})]}),"\n",(0,t.jsxs)(n.p,{children:["Most popular: ",(0,t.jsx)(n.strong,{children:"ROS-TCP-Connector"})]}),"\n",(0,t.jsx)(n.h3,{id:"gazebo-unity-bridge-architecture-diagram",children:"Gazebo-Unity Bridge Architecture Diagram"}),"\n",(0,t.jsx)(n.mermaid,{value:'graph TB\n    subgraph Gazebo["Gazebo (Physics Simulation)"]\n        A["Robot Dynamics"]\n        B["Sensor Simulation"]\n        C["World Physics"]\n    end\n\n    subgraph ROS["ROS 2 Middleware"]\n        D["Topics &\\nMessages"]\n        E["TCP Endpoint"]\n    end\n\n    subgraph Unity["Unity (Visualization & HRI)"]\n        F["Robot Rendering"]\n        G["Sensor Data Display"]\n        H["Human Avatar"]\n        I["Interactive UI"]\n    end\n\n    A --\x3e|Robot State| D\n    B --\x3e|Sensor Data| D\n    C --\x3e|Environment| D\n\n    D --\x3e|TCP Network| E\n    E --\x3e|TCP Network| D\n\n    E --\x3e|Pose Updates| F\n    E --\x3e|Point Cloud/Images| G\n    I --\x3e|User Input| E\n    H --\x3e|Avatar Position| E\n\n    style Gazebo fill:#e6f2ff\n    style ROS fill:#fff2e6\n    style Unity fill:#f2ffe6'}),"\n",(0,t.jsx)(n.h2,{id:"setting-up-ros-2-bridge",children:"Setting Up ROS 2 Bridge"}),"\n",(0,t.jsx)(n.h3,{id:"step-1-install-bridge-package",children:"Step 1: Install Bridge Package"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# On Linux (where Gazebo runs)\nsudo apt install ros-humble-turtlebot3-gazebo\nsudo apt install ros-humble-ros-tcp-endpoint\n"})}),"\n",(0,t.jsx)(n.h3,{id:"step-2-start-ros-2-tcp-bridge",children:"Step 2: Start ROS 2 TCP Bridge"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Terminal 1: ROS 2 core\nros2 run ros_tcp_endpoint default_server_endpoint --ros-args -p ROS_DOMAIN_ID:=0\n\n# Terminal 2: Gazebo\ngazebo my_world.world\n\n# Terminal 3: TCP bridge\nros2 launch ros_tcp_endpoint tcp_endpoint.launch.py\n"})}),"\n",(0,t.jsx)(n.h3,{id:"step-3-configure-unity",children:"Step 3: Configure Unity"}),"\n",(0,t.jsx)(n.p,{children:"In Unity:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Import ROS-TCP-Connector package"}),"\n",(0,t.jsx)(n.li,{children:"Create ROS Connector component"}),"\n",(0,t.jsxs)(n.li,{children:["Set IP address: ",(0,t.jsx)(n.code,{children:"localhost"})," (or IP of machine running ROS)"]}),"\n",(0,t.jsxs)(n.li,{children:["Set port: ",(0,t.jsx)(n.code,{children:"10000"})," (default)"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using RosMessageTypes.Geometry;\nusing Unity.Robotics.ROSTCPConnector;\nusing Unity.Robotics.ROSTCPConnector.ROSGeometry;\n\npublic class RobotController : MonoBehaviour\n{\n    private ROSConnection ros;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Subscribe<PoseMsg>("/robot/pose", OnRobotPose);\n    }\n\n    void OnRobotPose(PoseMsg pose)\n    {\n        // Update robot position in Unity based on Gazebo pose\n        transform.position = pose.position.As<Vector3>();\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"visualizing-robot-state-in-unity",children:"Visualizing Robot State in Unity"}),"\n",(0,t.jsx)(n.h3,{id:"real-time-pose-synchronization",children:"Real-Time Pose Synchronization"}),"\n",(0,t.jsx)(n.p,{children:"Subscribe to robot position from Gazebo:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'ros.Subscribe<PoseMsg>("/robot/base_link/pose", UpdateRobotPose);\n\nvoid UpdateRobotPose(PoseMsg pose)\n{\n    // Update Unity transform to match Gazebo pose\n    transform.position = pose.position.As<Vector3>();\n    transform.rotation = pose.orientation.As<Quaternion>();\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Result"}),": Robot in Unity moves exactly as it does in Gazebo, synchronized!"]}),"\n",(0,t.jsx)(n.h3,{id:"sensor-data-visualization",children:"Sensor Data Visualization"}),"\n",(0,t.jsx)(n.p,{children:"Visualize LiDAR data in Unity:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'ros.Subscribe<PointCloud2Msg>("/lidar/points", VisualizeLidar);\n\nvoid VisualizeLidar(PointCloud2Msg cloud)\n{\n    // Extract point cloud data\n    // Draw lines from robot to detected points\n    // Color points by distance\n    foreach (var point in cloud.data)\n    {\n        DrawDebugPoint(point, Color.red);\n    }\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"Visualize depth camera in Unity:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'ros.Subscribe<ImageMsg>("/depth_camera/depth", VisualizeDepth);\n\nvoid VisualizeDepth(ImageMsg depthImage)\n{\n    // Convert ROS image to Unity texture\n    Texture2D depthTexture = depthImage.ToTexture2D();\n    // Display on screen\n    GetComponent<RawImage>().texture = depthTexture;\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"human-robot-interaction-hri-scenarios",children:"Human-Robot Interaction (HRI) Scenarios"}),"\n",(0,t.jsx)(n.h3,{id:"scenario-1-human-avatar",children:"Scenario 1: Human Avatar"}),"\n",(0,t.jsx)(n.p,{children:"Create a humanoid avatar controlled by keyboard:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'void Update()\n{\n    // Keyboard input\n    float moveX = Input.GetAxis("Horizontal");\n    float moveZ = Input.GetAxis("Vertical");\n\n    // Move avatar\n    Vector3 move = new Vector3(moveX, 0, moveZ) * speed;\n    avatarTransform.Translate(move);\n\n    // Publish human position to ROS\n    PublishHumanPosition(avatarTransform.position);\n}\n\nvoid PublishHumanPosition(Vector3 pos)\n{\n    PoseMsg humanPose = new PoseMsg { position = pos.As<Vector3Msg>() };\n    ros.Publish("human/pose", humanPose);\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"Now Gazebo knows human position \u2192 robot can react!"}),"\n",(0,t.jsx)(n.h3,{id:"scenario-2-interactive-demonstration",children:"Scenario 2: Interactive Demonstration"}),"\n",(0,t.jsx)(n.p,{children:"User clicks to place objects in Unity:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'void Update()\n{\n    if (Input.GetMouseButtonDown(0))\n    {\n        Ray ray = Camera.main.ScreenPointToRay(Input.mousePosition);\n        if (Physics.Raycast(ray, out RaycastHit hit))\n        {\n            Vector3 clickPos = hit.point;\n            // Publish goal position to ROS\n            PublishGoal(clickPos);\n        }\n    }\n}\n\nvoid PublishGoal(Vector3 goal)\n{\n    GoalMsg goalMsg = new GoalMsg { position = goal.As<Vector3Msg>() };\n    ros.Publish("robot/goal", goalMsg);\n    // Gazebo\'s motion planner receives this goal and plans a path\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"scenario-3-handshake",children:"Scenario 3: Handshake"}),"\n",(0,t.jsx)(n.p,{children:"Simulate human-robot handshake:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'// Detect when robot hand reaches human hand\nif (Vector3.Distance(robotHand.position, humanHand.position) < 0.1f)\n{\n    // Trigger handshake animation\n    PlayHandshakeAnimation();\n\n    // Log to metrics\n    LogInteraction("handshake_successful");\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"advanced-visualization-motion-planning",children:"Advanced Visualization: Motion Planning"}),"\n",(0,t.jsx)(n.p,{children:"Visualize planned trajectories in Unity:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'ros.Subscribe<PathMsg>("/robot/planned_path", VisualizePath);\n\nvoid VisualizePath(PathMsg path)\n{\n    LineRenderer line = GetComponent<LineRenderer>();\n    line.positionCount = path.poses.Length;\n\n    for (int i = 0; i < path.poses.Length; i++)\n    {\n        Vector3 pos = path.poses[i].position.As<Vector3>();\n        line.SetPosition(i, pos);\n    }\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Result"}),": See the robot's planned path as a line in 3D space!"]}),"\n",(0,t.jsx)(n.h2,{id:"debugging-complex-behaviors",children:"Debugging Complex Behaviors"}),"\n",(0,t.jsx)(n.h3,{id:"overlay-sensor-information",children:"Overlay Sensor Information"}),"\n",(0,t.jsx)(n.p,{children:"Display sensor data on screen:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'void OnGUI()\n{\n    GUI.Label(new Rect(10, 10, 300, 100),\n        $"Robot Position: {robotPos}\\n" +\n        $"Nearest Obstacle: {nearestObstacle}m\\n" +\n        $"Battery: {batteryLevel}%\\n" +\n        $"Task: {currentTask}");\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"motion-analysis-tools",children:"Motion Analysis Tools"}),"\n",(0,t.jsx)(n.p,{children:"Record and playback motion:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"List<PoseMsg> recordedPoses = new List<PoseMsg>();\nbool isRecording = false;\n\nvoid RecordPose(PoseMsg pose)\n{\n    if (isRecording)\n        recordedPoses.Add(pose);\n}\n\nvoid PlaybackRecording()\n{\n    foreach (PoseMsg pose in recordedPoses)\n    {\n        UpdateRobotPose(pose);\n        yield return new WaitForSeconds(0.01f);  // Playback at ~100 Hz\n    }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,t.jsx)(n.h3,{id:"latency-the-synchronization-challenge",children:"Latency: The Synchronization Challenge"}),"\n",(0,t.jsx)(n.p,{children:"Ideal: 0ms latency (instant synchronization)\nRealistic: 10-100ms latency"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Gazebo publishes pose at 1ms \u2192 ROS middleware 2ms \u2192 Unity receives 3ms\nTotal: ~3-5ms of latency (good!)\n\nBut if:\nGazebo publishes at 1ms \u2192 Network delay 50ms \u2192 ROS 2ms \u2192 Unity receives 53ms\nTotal: ~50ms of latency (noticeable)\n\nSolution: Optimize network, reduce publish frequency, or accept latency\n"})}),"\n",(0,t.jsx)(n.h3,{id:"frame-rate-management",children:"Frame Rate Management"}),"\n",(0,t.jsx)(n.p,{children:"Keep both simulators running smoothly:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"// Unity: Target 60 FPS\nTime.targetFrameRate = 60;\n\n// Gazebo: Target real-time\n// In Gazebo config: <real_time_factor>1.0</real_time_factor>\n\n// ROS publish rate: Not too fast (network overhead)\n// Typical: 10-30 Hz for visualization\n"})}),"\n",(0,t.jsx)(n.h2,{id:"deployment-scenarios",children:"Deployment Scenarios"}),"\n",(0,t.jsx)(n.h3,{id:"local-machine-development",children:"Local Machine (Development)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Machine A: Gazebo + ROS 2\nMachine A: Unity\nConnection: localhost (0ms latency)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"two-machines-remote",children:"Two Machines (Remote)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Machine A: Gazebo + ROS 2 (Linux)\nMachine B: Unity (Windows/Mac)\nConnection: Network (10-50ms latency)\nSetup: ROS 2 discovery across network\n"})}),"\n",(0,t.jsx)(n.h3,{id:"cloud-based",children:"Cloud-Based"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Cloud Server: Gazebo + ROS 2\nLocal Machine: Unity\nConnection: Internet (50-200ms latency)\nRisk: High latency may break real-time interaction\n"})}),"\n",(0,t.jsx)(n.h2,{id:"cross-module-connections",children:"Cross-Module Connections"}),"\n",(0,t.jsx)(n.p,{children:"Unity visualization completes the simulation-to-reality pipeline:"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"From Module 1 (ROS 2 Fundamentals)"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS 2 bridge"})," (this chapter) extends Module 1's communication concepts"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Autonomous agents"})," (Module 1, Chapter 2) receive feedback from Unity HRI"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"URDF models"})," (Module 1, Chapter 3) are rendered with photorealistic graphics in Unity"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"To Module 3 (Isaac Sim & Perception)"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Photorealistic rendering"})," prepares robots for ",(0,t.jsx)(n.strong,{children:"visual perception tasks"})," in Module 3"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Human avatars"})," (this chapter) enable ",(0,t.jsx)(n.strong,{children:"human-robot collaboration"})," testing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Motion visualization"})," validates ",(0,t.jsx)(n.strong,{children:"VSLAM and navigation"})," algorithms"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"To Module 4 (VLA Pipeline)"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"HRI scenarios"})," (this chapter) demonstrate language-grounded manipulation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Interactive demonstrations"})," enable ",(0,t.jsx)(n.strong,{children:"task learning from visual feedback"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real-time synchronization"})," bridges simulated and real robot execution"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"creating-a-complete-hri-demonstration",children:"Creating a Complete HRI Demonstration"}),"\n",(0,t.jsx)(n.h3,{id:"step-1-design-scenario",children:"Step 1: Design Scenario"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'Scene: Office environment\n- Humanoid robot\n- Human avatar\n- Table with objects\n- Task: "Hand-over" interaction\n'})}),"\n",(0,t.jsx)(n.h3,{id:"step-2-implement-robot-behavior-ros",children:"Step 2: Implement Robot Behavior (ROS)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# ROS 2 node for robot control\ndef human_detected_callback(human_pose):\n    # React to human presence\n    move_towards_human()\n\n    # Offer handshake\n    extend_hand()\n"})}),"\n",(0,t.jsx)(n.h3,{id:"step-3-implement-hri-unity",children:"Step 3: Implement HRI (Unity)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"// Human player controls avatar\n// Avatar position published to ROS\n// Robot reacts to human proximity\n// Handshake animation triggers\n"})}),"\n",(0,t.jsx)(n.h3,{id:"step-4-visualize-and-debug",children:"Step 4: Visualize and Debug"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Real-time display:\n- Robot position\n- Human position\n- Distance between them\n- Sensor data overlay\n- Planned motion path\n"})}),"\n",(0,t.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,t.jsxs)(n.p,{children:["\u2713 ",(0,t.jsx)(n.strong,{children:"ROS 2 bridge"})," connects Gazebo (physics) to Unity (graphics)\n\u2713 ",(0,t.jsx)(n.strong,{children:"Synchronization"})," keeps simulations aligned in real-time\n\u2713 ",(0,t.jsx)(n.strong,{children:"HRI scenarios"})," require bidirectional communication\n\u2713 ",(0,t.jsx)(n.strong,{children:"Latency"})," is manageable with good network design\n\u2713 ",(0,t.jsx)(n.strong,{children:"Visualization"})," helps debug complex robot behaviors\n\u2713 ",(0,t.jsx)(n.strong,{children:"Motion planning"})," can be visualized as trajectories\n\u2713 ",(0,t.jsx)(n.strong,{children:"Demonstrations"})," can showcase robot capabilities to stakeholders"]}),"\n",(0,t.jsx)(n.h2,{id:"acronym-reference",children:"Acronym Reference"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Acronym"}),(0,t.jsx)(n.th,{children:"Full Name"}),(0,t.jsx)(n.th,{children:"Definition"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Unity"})}),(0,t.jsx)(n.td,{children:"Unity Game Engine"}),(0,t.jsx)(n.td,{children:"Cross-platform 3D graphics engine for visualization and interactive content"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"ROS 2"})}),(0,t.jsx)(n.td,{children:"Robot Operating System 2"}),(0,t.jsx)(n.td,{children:"Middleware for robot communication and software integration (from Module 1)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Bridge"})}),(0,t.jsx)(n.td,{children:"Communication Protocol"}),(0,t.jsx)(n.td,{children:"Software layer connecting two systems (Gazebo \u2194 Unity via ROS 2 topics)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"TCP"})}),(0,t.jsx)(n.td,{children:"Transmission Control Protocol"}),(0,t.jsx)(n.td,{children:"Reliable network protocol for ROS 2 TCP connector"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Socket"})}),(0,t.jsx)(n.td,{children:"Network Connection"}),(0,t.jsx)(n.td,{children:"Endpoint for bidirectional communication over TCP/IP network"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Rendering"})}),(0,t.jsx)(n.td,{children:"Graphics Computation"}),(0,t.jsx)(n.td,{children:"Process of generating 3D images from scene data"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Photorealistic"})}),(0,t.jsx)(n.td,{children:"Physically-Based Rendering"}),(0,t.jsx)(n.td,{children:"High-fidelity graphics matching real-world appearance and lighting"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"HRI"})}),(0,t.jsx)(n.td,{children:"Human-Robot Interaction"}),(0,t.jsx)(n.td,{children:"Study and simulation of how humans and robots interact collaboratively"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Avatar"})}),(0,t.jsx)(n.td,{children:"Virtual Character"}),(0,t.jsx)(n.td,{children:"Digital representation of a human for interaction scenarios"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Pipeline"})}),(0,t.jsx)(n.td,{children:"Processing Flow"}),(0,t.jsx)(n.td,{children:"Series of stages transforming Gazebo physics into Unity visualization"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(n.p,{children:"You've now completed Module 2! You can:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u2705 Configure realistic physics in Gazebo"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Build complex simulated worlds"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Attach realistic sensors"}),"\n",(0,t.jsx)(n.li,{children:"\u2705 Visualize in Unity and create HRI scenarios"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Combined with ",(0,t.jsx)(n.strong,{children:"Module 1 (ROS 2)"}),", you can now build complete simulation pipelines for humanoid robots!"]}),"\n",(0,t.jsx)(n.h3,{id:"what-comes-next",children:"What Comes Next?"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Module 3"}),": Isaac Sim (advanced photorealistic simulation)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Module 4"}),": Voice commands and AI agents"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Advanced Topics"}),": Motion planning, learning from simulation"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Learning Outcome"}),": You can now connect Gazebo and Unity, synchronize robot state in real-time, and create interactive human-robot interaction demonstrations."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Congratulations on completing Module 2!"})," \ud83c\udf89"]}),"\n",(0,t.jsx)(n.p,{children:"You're now a simulation expert. Your digital twins can perceive, plan, and interact with humans!"})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>r});var o=i(6540);const t={},s=o.createContext(t);function a(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);